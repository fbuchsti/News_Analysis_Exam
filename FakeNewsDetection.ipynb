{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAKE NEWS DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook contains all relevant computations and investigations for the exam in DS821: News and Market Sentiment Analysis. The structure is predominantly corresponding to the structure of the report. However, most section is labeled with the number corresponding to the section of the report for transparency.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import math\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. DATA LOAD AND INSPECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "fake = pd.read_csv(\"/Users/FrederikkeB/Dropbox/DS 3/News Analysis/Exam/data/Fake.csv\")\n",
    "true = pd.read_csv(\"/Users/FrederikkeB/Dropbox/DS 3/News Analysis/Exam/data/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataframe\n",
    "fake.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataframe\n",
    "true.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign class labels to each dataframe\n",
    "true[\"label\"] = 0\n",
    "fake[\"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to two dataframes together \n",
    "df = pd.concat([fake, true], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44898, 5)\n",
      "label\n",
      "1    23481\n",
      "0    21417\n",
      "Name: count, dtype: int64\n",
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# inspect data frame\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df[\"label\"].value_counts())\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6252)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "df.duplicated(subset=[\"text\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed: 6252\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates \n",
    "len_before = len(df)\n",
    "df = df.drop_duplicates(subset=[\"text\"], keep=\"first\")\n",
    "len_after = len(df)\n",
    "\n",
    "print(\"Duplicates removed:\", len_before - len_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.992025\n",
       "1    0.000000\n",
       "Name: starts_with_reuters, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect how many articles comes from reuters\n",
    "df[\"starts_with_reuters\"] = df[\"text\"].str.lower().str.contains(\n",
    "    r\"^.*\\(\\s*reuters\\s*\\)\\s*-\", regex=True, na=False\n",
    ")\n",
    "# divide by class\n",
    "df.groupby(\"label\")[\"starts_with_reuters\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove potential metadata in the beginning of each body text\n",
    "def remove_leading_metadata(text):\n",
    "    pattern = r\"^[A-Z\\s\\/]+\\s*\\([A-Za-z]+\\)\\s*[–—-]\\s+\"\n",
    "    return re.sub(pattern, \"\", text).strip()\n",
    "\n",
    "# run on text column\n",
    "df[\"text_clean\"] = df[\"text\"].apply(remove_leading_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.992733\n",
       "1    0.214437\n",
       "Name: metadata_removed, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "df[\"metadata_removed\"] = df[\"text\"] != df[\"text_clean\"]\n",
    "df.groupby(\"label\")[\"metadata_removed\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.000000\n",
       "1    0.208823\n",
       "Name: url_count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the occurence of url in articles\n",
    "df[\"url_count\"] = df[\"text\"].str.count(r\"http[s]?://\")\n",
    "\n",
    "# print the difference between classes\n",
    "df.groupby(\"label\")[\"url_count\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     Clarke, email search warrant filed https://t.c...\n",
       "3     by July 24 next year. https://t.co/Fg7VacxRtJ ...\n",
       "3     of an internal server error: https://t.co/zrWp...\n",
       "3     appears to be on all https://t.co/dkhw0AlHB4 p...\n",
       "3     2017It s also all over https://t.co/ayBlGmk65Z...\n",
       "16    this to the Haunted Mansion? https://t.co/XrOv...\n",
       "16    looking as a fucking Pokemon. https://t.co/HFY...\n",
       "16    the future of the planet. https://t.co/65FhbQH...\n",
       "19    don t. You don t https://t.co/7lHYkIloyz Senat...\n",
       "19    to clean house of partisans https://t.co/g8Swg...\n",
       "Name: url_contexts, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect urls context in articles\n",
    "def url_context(text, window=5):\n",
    "    tokens = text.split()\n",
    "    contexts = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.startswith(\"http\"):\n",
    "            start = max(i - window, 0)\n",
    "            end = min(i + window + 1, len(tokens))\n",
    "            contexts.append(\" \".join(tokens[start:end]))\n",
    "    return contexts\n",
    "\n",
    "df[\"url_contexts\"] = df[\"text\"].apply(url_context)\n",
    "\n",
    "# print observations including urls\n",
    "fake_contexts = df[df[\"label\"] == 1][\"url_contexts\"].explode().dropna()\n",
    "fake_contexts.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove web related entities from body text \n",
    "def remove_urls_and_html(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)   \n",
    "    text = re.sub(r\"&\\w+;\", \" \", text)            \n",
    "    return text\n",
    "\n",
    "df[\"text_clean\"] = df[\"text_clean\"].apply(remove_urls_and_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define web specific noise\n",
    "noise = {\n",
    "    \"https\", \"http\", \"www\", \"amp\", \"quot\", \"cdata\", \"js\",\n",
    "    \"pic\", \"youtu\", \"flickr\", \"getty\", \"wikimedia\",\n",
    "    \"screenshot\", \"src\", \"createelement\", \"getelementbyid\",\n",
    "    \"getelementsbytagname\", \"parentnode\", \"insertbefore\",\n",
    "    \"jssdk\", \"xfbml\", \"filessupport\", \"21wire\", \n",
    "}\n",
    "\n",
    "# translate to regex\n",
    "noise_pattern = re.compile(\n",
    "    r\"\\b(\" + \"|\".join(map(re.escape, noise)) + r\")\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "# remove noise\n",
    "def remove_noise(text):\n",
    "    return noise_pattern.sub(\"\", text)\n",
    "\n",
    "# apply to cleaned text\n",
    "df[\"text_clean\"] = df[\"text_clean\"].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase body text\n",
    "df[\"text_clean\"] = df[\"text_clean\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stopwords\n",
    "stopwords = set(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function combining each tokenization step\n",
    "def tokenize(text):\n",
    "\n",
    "    # extract alphabetic tokens\n",
    "    tokens = re.findall(r\"[a-zA-Z]+\", text)\n",
    "\n",
    "    # remove stopwords\n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "\n",
    "    # remove tokens with less than 2 characters\n",
    "    tokens = [t for t in tokens if len(t) > 2]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# apply to cleaned text \n",
    "df[\"tokens\"] = df[\"text_clean\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>starts_with_reuters</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>metadata_removed</th>\n",
       "      <th>url_count</th>\n",
       "      <th>url_contexts</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>donald trump just couldn t wish all americans ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[donald, trump, just, couldn, wish, americans,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>house intelligence committee chairman devin nu...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[house, intelligence, committee, chairman, dev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "\n",
       "                date  label  starts_with_reuters  \\\n",
       "0  December 31, 2017      1                False   \n",
       "1  December 31, 2017      1                False   \n",
       "\n",
       "                                          text_clean  metadata_removed  \\\n",
       "0  donald trump just couldn t wish all americans ...             False   \n",
       "1  house intelligence committee chairman devin nu...             False   \n",
       "\n",
       "   url_count url_contexts                                             tokens  \n",
       "0          0           []  [donald, trump, just, couldn, wish, americans,...  \n",
       "1          0           []  [house, intelligence, committee, chairman, dev...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect clean dataframe\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LENGTH AND STYLE DIFFERENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (38591, 11)\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "0    21191\n",
      "1    17400\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "label\n",
      "0    0.549118\n",
      "1    0.450882\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check basic properties\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "print(\"\\nClass proportions:\")\n",
    "print(df[\"label\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">char_count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2359.007645</td>\n",
       "      <td>2197.0</td>\n",
       "      <td>1684.412767</td>\n",
       "      <td>382.210655</td>\n",
       "      <td>356.0</td>\n",
       "      <td>273.922864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake</th>\n",
       "      <td>2550.922299</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>2195.548446</td>\n",
       "      <td>426.502759</td>\n",
       "      <td>377.0</td>\n",
       "      <td>355.087980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       char_count                       word_count                   \n",
       "             mean  median          std        mean median         std\n",
       "True  2359.007645  2197.0  1684.412767  382.210655  356.0  273.922864\n",
       "Fake  2550.922299  2233.0  2195.548446  426.502759  377.0  355.087980"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic length features\n",
    "df[\"char_count\"] = df[\"text_clean\"].str.len()\n",
    "df[\"word_count\"] = df[\"text_clean\"].str.split().str.len()\n",
    "\n",
    "# summary statistics per class\n",
    "length_stats = df.groupby(\"label\")[[\"char_count\", \"word_count\"]].agg(\n",
    "    [\"mean\", \"median\", \"std\"]\n",
    ")\n",
    "\n",
    "# print results\n",
    "length_stats.index = [\"True\", \"Fake\"]\n",
    "length_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words – True news:\n",
      "[('said', 97814), ('trump', 54066), ('president', 27857), ('state', 20781), ('government', 18550), ('house', 16462), ('states', 16412), ('republican', 16135), ('new', 15775), ('united', 15159), ('people', 15076), ('year', 14583), ('told', 14061), ('party', 12589), ('election', 12171), ('reuters', 10897), ('campaign', 10534), ('donald', 10370), ('security', 10006), ('percent', 9920), ('north', 9696), ('clinton', 9464), ('white', 9452), ('court', 9356), ('obama', 9330), ('senate', 9161), ('country', 8779), ('china', 8714), ('minister', 8544), ('officials', 8364), ('week', 8333), ('democratic', 8319), ('tuesday', 8189), ('foreign', 8170), ('national', 8139), ('law', 8133), ('administration', 8100), ('tax', 8063), ('including', 8010), ('presidential', 7983), ('military', 7980), ('russia', 7947), ('wednesday', 7861), ('years', 7744), ('political', 7627), ('thursday', 7564), ('statement', 7490), ('did', 7378), ('time', 7347), ('friday', 7257), ('support', 7092), ('korea', 7076), ('monday', 7006), ('group', 6951), ('vote', 6889), ('called', 6718), ('republicans', 6708), ('say', 6605), ('office', 6486), ('million', 6422), ('congress', 6408), ('federal', 6392), ('committee', 6355), ('washington', 6151), ('department', 6112), ('according', 6076), ('official', 6029), ('news', 5957), ('police', 5951), ('saying', 5900), ('russian', 5893), ('trade', 5885), ('deal', 5836), ('policy', 5718), ('iran', 5708), ('leader', 5647), ('month', 5645), ('secretary', 5582), ('general', 5410), ('public', 5396), ('make', 5354), ('nuclear', 5263), ('democrats', 5192), ('rights', 5185), ('countries', 5183), ('south', 5084), ('city', 5038), ('senator', 4943), ('meeting', 4905), ('american', 4836), ('leaders', 4817), ('world', 4762), ('war', 4706), ('international', 4670), ('spokesman', 4636), ('like', 4634), ('work', 4630), ('long', 4629), ('agency', 4511), ('day', 4507)]\n",
      "\n",
      "Top words – Fake news:\n",
      "[('trump', 68632), ('said', 24803), ('people', 21204), ('president', 20854), ('just', 16790), ('donald', 15396), ('like', 14375), ('clinton', 13553), ('obama', 13410), ('time', 10712), ('new', 10409), ('white', 10311), ('news', 10258), ('hillary', 9991), ('state', 9496), ('image', 9494), ('twitter', 9315), ('right', 8899), ('campaign', 8835), ('featured', 8434), ('house', 8428), ('know', 8410), ('don', 8231), ('american', 8204), ('america', 8162), ('republican', 7986), ('going', 7976), ('media', 7870), ('states', 7588), ('year', 7398), ('did', 7313), ('make', 7309), ('country', 7099), ('way', 6933), ('say', 6895), ('election', 6807), ('think', 6803), ('republicans', 6696), ('told', 6598), ('years', 6573), ('video', 6565), ('government', 6270), ('police', 6210), ('party', 6071), ('women', 6045), ('united', 5903), ('according', 5824), ('want', 5795), ('com', 5730), ('world', 5575), ('black', 5540), ('law', 5421), ('says', 5337), ('man', 5275), ('day', 5244), ('political', 5196), ('fact', 5133), ('americans', 5102), ('national', 5075), ('really', 5036), ('pic', 5023), ('called', 4846), ('public', 4780), ('vote', 4575), ('didn', 4521), ('watch', 4517), ('doesn', 4492), ('support', 4453), ('presidential', 4437), ('russia', 4418), ('good', 4413), ('fox', 4332), ('office', 4331), ('images', 4301), ('does', 4253), ('actually', 4153), ('getty', 4138), ('administration', 4132), ('realdonaldtrump', 4128), ('saying', 4123), ('need', 4003), ('court', 3937), ('asked', 3926), ('come', 3909), ('security', 3869), ('gop', 3869), ('things', 3869), ('times', 3855), ('left', 3849), ('story', 3847), ('got', 3840), ('federal', 3839), ('group', 3835), ('washington', 3799), ('fbi', 3780), ('work', 3776), ('million', 3772), ('thing', 3760), ('money', 3718), ('department', 3700)]\n"
     ]
    }
   ],
   "source": [
    "# function extracting most used words in each class\n",
    "def top_words_from_tokens(token_series, n=100):\n",
    "    tokens = [t for tokens in token_series for t in tokens]\n",
    "    return Counter(tokens).most_common(n)\n",
    "\n",
    "# apply function and store in each list\n",
    "top_true = top_words_from_tokens(df[df[\"label\"] == 0][\"tokens\"], 100)\n",
    "top_fake = top_words_from_tokens(df[df[\"label\"] == 1][\"tokens\"], 100)\n",
    "\n",
    "# print\n",
    "print(\"Top words – True news:\")\n",
    "print(top_true)\n",
    "\n",
    "print(\"\\nTop words – Fake news:\")\n",
    "print(top_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 SENTITMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINBERT SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "# define FinBERT-model\n",
    "finbert_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"ProsusAI/finbert\",\n",
    "    device=\"mps\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function extracting scores from model\n",
    "def finbert_score(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return np.nan   \n",
    "\n",
    "    out = finbert_model(text)[0]\n",
    "    label = out[\"label\"]\n",
    "    score = out[\"score\"]\n",
    "\n",
    "    if label == \"positive\":\n",
    "        return score\n",
    "    elif label == \"negative\":\n",
    "        return -score\n",
    "    else:  # neutral\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate scores to labels\n",
    "def finbert_label(score, eps=0.1):\n",
    "    if pd.isna(score):\n",
    "        return np.nan\n",
    "    if score > eps:\n",
    "        return \"positive\"\n",
    "    if score < -eps:\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/cnk8h6ld5nj287lndrx4g8kh0000gn/T/ipykernel_63248/124310353.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=2000, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# define a subset  \n",
    "finbert_subset = (\n",
    "    df\n",
    "    .groupby(\"label\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=2000, random_state=42))\n",
    ")\n",
    "\n",
    "# apply model to subset \n",
    "finbert_subset[\"finbert_score\"] = finbert_subset[\"text_clean\"].apply(finbert_score)\n",
    "finbert_subset[\"finbert_label\"] = finbert_subset[\"finbert_score\"].apply(\n",
    "    lambda x: finbert_label(x, eps=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finbert_label\n",
       "neutral     0.507762\n",
       "negative    0.459940\n",
       "positive    0.032298\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results\n",
    "finbert_subset[\"finbert_label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>finbert_label</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True news</th>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake news</th>\n",
       "      <td>0.309428</td>\n",
       "      <td>0.686058</td>\n",
       "      <td>0.004514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "finbert_label  negative   neutral  positive\n",
       "True news      0.610000  0.330000  0.060000\n",
       "Fake news      0.309428  0.686058  0.004514"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results by class \n",
    "finbert_by_class = (\n",
    "    finbert_subset\n",
    "    .groupby(\"label\")[\"finbert_label\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "finbert_by_class.index = [\"True news\", \"Fake news\"]\n",
    "finbert_by_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROBERTA SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "# define RoBERTa-model \n",
    "roberta_model = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    device=\"mps\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function extracting scores from model\n",
    "def roberta_score(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return np.nan   \n",
    "\n",
    "    out = roberta_model(text)[0]\n",
    "    label = out[\"label\"]\n",
    "    score = out[\"score\"]\n",
    "\n",
    "    if label == \"positive\":\n",
    "        return score\n",
    "    elif label == \"negative\":\n",
    "        return -score\n",
    "    else:  # neutral\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate scores to labels\n",
    "def roberta_label(score, eps=0.1):\n",
    "    if pd.isna(score):\n",
    "        return np.nan\n",
    "    if score > eps:\n",
    "        return \"positive\"\n",
    "    if score < -eps:\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qw/cnk8h6ld5nj287lndrx4g8kh0000gn/T/ipykernel_63248/521462801.py:4: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=2000, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# define a subset\n",
    "roberta_subset = (\n",
    "    df\n",
    "    .groupby(\"label\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=2000, random_state=42))\n",
    ")\n",
    "\n",
    "# apply model to subset\n",
    "roberta_subset[\"roberta_score\"] = roberta_subset[\"text_clean\"].apply(roberta_score)\n",
    "roberta_subset[\"roberta_label\"] = roberta_subset[\"roberta_score\"].apply(\n",
    "    lambda x: roberta_label(x, eps=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roberta_label\n",
       "neutral     0.586880\n",
       "negative    0.365048\n",
       "positive    0.048072\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results\n",
    "roberta_subset[\"roberta_label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>roberta_label</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True news</th>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake news</th>\n",
       "      <td>0.576229</td>\n",
       "      <td>0.363089</td>\n",
       "      <td>0.060682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "roberta_label  negative   neutral  positive\n",
       "True news      0.154500  0.810000  0.035500\n",
       "Fake news      0.576229  0.363089  0.060682"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results by class \n",
    "roberta_by_class = (\n",
    "    roberta_subset\n",
    "    .groupby(\"label\")[\"roberta_label\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "roberta_by_class.index = [\"True news\", \"Fake news\"]\n",
    "roberta_by_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 VOCABULARY CONTRASTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words more characteristic of Fake news:\n",
      "\n",
      "featured        4.43\n",
      "gop             3.72\n",
      "com             3.44\n",
      "image           3.26\n",
      "rep             3.13\n",
      "screen          3.07\n",
      "literally       3.04\n",
      "youtube         2.90\n",
      "images          2.89\n",
      "wire            2.87\n",
      "realdonaldtrump 2.78\n",
      "stupid          2.57\n",
      "racist          2.54\n",
      "wonder          2.48\n",
      "isn             2.35\n",
      "campus          2.29\n",
      "lie             2.26\n",
      "interesting     2.25\n",
      "wasn            2.22\n",
      "mrs             2.22\n",
      "kids            2.22\n",
      "racism          2.19\n",
      "hate            2.17\n",
      "sounds          2.15\n",
      "breitbart       2.15\n",
      "perfectly       2.14\n",
      "apparently      2.14\n",
      "joke            2.14\n",
      "couldn          2.13\n",
      "guy             2.12\n",
      "watch           2.12\n",
      "narrative       2.09\n",
      "hell            2.06\n",
      "truth           2.05\n",
      "explained       2.05\n",
      "ridiculous      2.04\n",
      "fun             2.03\n",
      "actually        2.01\n",
      "crazy           1.99\n",
      "video           1.98\n",
      "remember        1.97\n",
      "reads           1.97\n",
      "soros           1.97\n",
      "bigotry         1.96\n",
      "clip            1.96\n",
      "perfect         1.96\n",
      "tonight         1.95\n",
      "mouth           1.95\n",
      "girl            1.94\n",
      "color           1.94\n",
      "\n",
      "Words more characteristic of True news:\n",
      "\n",
      "reuters         3.58\n",
      "kurdish         3.45\n",
      "referendum      3.34\n",
      "ministry        3.21\n",
      "spain           3.13\n",
      "parliament      3.10\n",
      "macron          2.95\n",
      "pyongyang       2.89\n",
      "province        2.88\n",
      "regional        2.80\n",
      "brexit          2.78\n",
      "lebanon         2.77\n",
      "ministers       2.71\n",
      "bloc            2.70\n",
      "taiwan          2.68\n",
      "nov             2.65\n",
      "erdogan         2.60\n",
      "corp            2.60\n",
      "duterte         2.60\n",
      "baghdad         2.59\n",
      "britain         2.59\n",
      "independence    2.57\n",
      "minister        2.55\n",
      "talks           2.53\n",
      "japan           2.52\n",
      "tehran          2.43\n",
      "abe             2.43\n",
      "negotiations    2.43\n",
      "region          2.42\n",
      "turkish         2.36\n",
      "mattis          2.34\n",
      "independently   2.34\n",
      "brazil          2.34\n",
      "peninsula       2.33\n",
      "asia            2.32\n",
      "militants       2.32\n",
      "korean          2.32\n",
      "currency        2.30\n",
      "missile         2.29\n",
      "neighboring     2.28\n",
      "european        2.25\n",
      "northern        2.24\n",
      "china           2.23\n",
      "philippines     2.23\n",
      "defence         2.23\n",
      "ballistic       2.21\n",
      "sept            2.21\n",
      "stability       2.21\n",
      "disputed        2.20\n",
      "militant        2.20\n"
     ]
    }
   ],
   "source": [
    "# function counting tokens in a series of token lists\n",
    "def count_tokens(token_series):\n",
    "    return Counter([t for tokens in token_series for t in tokens])\n",
    "\n",
    "\n",
    "# token counts per class\n",
    "true_counts = count_tokens(df[df[\"label\"] == 0][\"tokens\"])\n",
    "fake_counts = count_tokens(df[df[\"label\"] == 1][\"tokens\"])\n",
    "\n",
    "min_freq = 50  \n",
    "\n",
    "\n",
    "# define a shared vocabulary of tokens appearing sufficiently often in both classes\n",
    "vocab = {\n",
    "    w for w in fake_counts\n",
    "    if fake_counts[w] >= min_freq and true_counts.get(w, 0) >= min_freq\n",
    "}\n",
    "\n",
    "\n",
    "# find words more characteristic of fake news\n",
    "rel_fake = {\n",
    "    w: math.log((fake_counts[w] + 1) / (true_counts[w] + 1))\n",
    "    for w in vocab\n",
    "}\n",
    "# sort values\n",
    "top_fake = sorted(\n",
    "    rel_fake.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:50]\n",
    "\n",
    "print(\"Words more characteristic of Fake news:\\n\")\n",
    "for w, s in top_fake:\n",
    "    print(f\"{w:<15} {s:.2f}\")\n",
    "\n",
    "\n",
    "# find words more characteristic of true news\n",
    "rel_true = {\n",
    "    w: math.log((true_counts[w] + 1) / (fake_counts[w] + 1))\n",
    "    for w in vocab\n",
    "}\n",
    "# sort values\n",
    "top_true = sorted(\n",
    "    rel_true.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")[:50]\n",
    "\n",
    "print(\"\\nWords more characteristic of True news:\\n\")\n",
    "for w, s in top_true:\n",
    "    print(f\"{w:<15} {s:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPIC MODELLING: LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = df[df[\"label\"] == 0]\n",
    "df_fake = df[df[\"label\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lda(token_lists, num_topics=7, no_below=20, no_above=0.9):\n",
    "    \n",
    "    # Create dictionary\n",
    "    dictionary = Dictionary(token_lists)\n",
    "    dictionary.filter_extremes(no_below=no_below, no_above=no_above)\n",
    "    \n",
    "    # Create BoW corpus\n",
    "    corpus_bow = [dictionary.doc2bow(doc) for doc in token_lists]\n",
    "    \n",
    "    # Train LDA\n",
    "    lda = LdaModel(\n",
    "        corpus=corpus_bow,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        passes=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return lda, dictionary, corpus_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_true, dict_true, corpus_true = run_lda(\n",
    "    df_true[\"tokens\"].tolist(),\n",
    "    num_topics=7\n",
    ")\n",
    "\n",
    "lda_fake, dict_fake, corpus_fake = run_lda(\n",
    "    df_fake[\"tokens\"].tolist(),\n",
    "    num_topics=7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics – True news\n",
      "(0, '0.023*\"party\" + 0.018*\"election\" + 0.012*\"vote\" + 0.012*\"republican\" + 0.011*\"trump\" + 0.011*\"percent\" + 0.008*\"democratic\" + 0.008*\"clinton\" + 0.008*\"presidential\" + 0.007*\"voters\"')\n",
      "(1, '0.013*\"state\" + 0.011*\"military\" + 0.010*\"islamic\" + 0.010*\"forces\" + 0.009*\"government\" + 0.008*\"syria\" + 0.008*\"turkey\" + 0.007*\"iraq\" + 0.007*\"saudi\" + 0.007*\"killed\"')\n",
      "(2, '0.011*\"court\" + 0.011*\"police\" + 0.010*\"people\" + 0.007*\"myanmar\" + 0.007*\"rights\" + 0.007*\"government\" + 0.006*\"rohingya\" + 0.005*\"state\" + 0.005*\"year\" + 0.005*\"law\"')\n",
      "(3, '0.045*\"trump\" + 0.016*\"president\" + 0.010*\"house\" + 0.009*\"white\" + 0.008*\"campaign\" + 0.007*\"donald\" + 0.007*\"russia\" + 0.007*\"russian\" + 0.005*\"department\" + 0.005*\"committee\"')\n",
      "(4, '0.010*\"tax\" + 0.008*\"percent\" + 0.008*\"billion\" + 0.007*\"government\" + 0.007*\"house\" + 0.007*\"year\" + 0.006*\"million\" + 0.006*\"budget\" + 0.006*\"new\" + 0.006*\"companies\"')\n",
      "(5, '0.011*\"north\" + 0.009*\"minister\" + 0.009*\"korea\" + 0.008*\"china\" + 0.008*\"united\" + 0.007*\"government\" + 0.007*\"president\" + 0.007*\"states\" + 0.006*\"nuclear\" + 0.006*\"european\"')\n",
      "(6, '0.006*\"mexico\" + 0.006*\"people\" + 0.005*\"oil\" + 0.005*\"year\" + 0.005*\"hurricane\" + 0.005*\"power\" + 0.005*\"million\" + 0.004*\"florida\" + 0.004*\"reuters\" + 0.004*\"trade\"')\n",
      "\n",
      "Topics – Fake news\n",
      "(0, '0.007*\"people\" + 0.006*\"government\" + 0.006*\"state\" + 0.005*\"new\" + 0.005*\"states\" + 0.005*\"america\" + 0.005*\"american\" + 0.005*\"million\" + 0.004*\"money\" + 0.004*\"world\"')\n",
      "(1, '0.009*\"said\" + 0.008*\"president\" + 0.008*\"fbi\" + 0.008*\"obama\" + 0.007*\"russia\" + 0.007*\"state\" + 0.007*\"syria\" + 0.006*\"security\" + 0.006*\"government\" + 0.005*\"russian\"')\n",
      "(2, '0.021*\"women\" + 0.013*\"said\" + 0.012*\"republicans\" + 0.011*\"house\" + 0.009*\"ryan\" + 0.007*\"health\" + 0.007*\"senate\" + 0.007*\"abortion\" + 0.007*\"care\" + 0.007*\"rep\"')\n",
      "(3, '0.019*\"clinton\" + 0.018*\"news\" + 0.018*\"media\" + 0.013*\"hillary\" + 0.009*\"wire\" + 0.007*\"story\" + 0.006*\"new\" + 0.006*\"campaign\" + 0.006*\"fox\" + 0.006*\"cnn\"')\n",
      "(4, '0.021*\"trump\" + 0.015*\"clinton\" + 0.013*\"republican\" + 0.013*\"party\" + 0.013*\"election\" + 0.012*\"hillary\" + 0.010*\"vote\" + 0.010*\"campaign\" + 0.008*\"democratic\" + 0.008*\"presidential\"')\n",
      "(5, '0.053*\"trump\" + 0.013*\"president\" + 0.012*\"donald\" + 0.010*\"just\" + 0.010*\"people\" + 0.009*\"like\" + 0.008*\"said\" + 0.007*\"twitter\" + 0.007*\"obama\" + 0.006*\"white\"')\n",
      "(6, '0.011*\"said\" + 0.010*\"police\" + 0.007*\"black\" + 0.007*\"people\" + 0.004*\"year\" + 0.004*\"gun\" + 0.004*\"school\" + 0.004*\"man\" + 0.004*\"video\" + 0.004*\"white\"')\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics – True news\")\n",
    "for t in lda_true.print_topics(num_words=10):\n",
    "    print(t)\n",
    "\n",
    "print(\"\\nTopics – Fake news\")\n",
    "for t in lda_fake.print_topics(num_words=10):\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.4828385696300357), np.float64(0.4477192467662035))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get coherence score for each class\n",
    "coh_true = CoherenceModel(\n",
    "    model=lda_true,\n",
    "    texts=df_true[\"tokens\"].tolist(),\n",
    "    dictionary=dict_true,\n",
    "    coherence=\"c_v\"\n",
    ").get_coherence()\n",
    "\n",
    "coh_fake = CoherenceModel(\n",
    "    model=lda_fake,\n",
    "    texts=df_fake[\"tokens\"].tolist(),\n",
    "    dictionary=dict_fake,\n",
    "    coherence=\"c_v\"\n",
    ").get_coherence()\n",
    "\n",
    "coh_true, coh_fake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for all classification models\n",
    "X = df[\"text_clean\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# split traning and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 NAÏVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define nb-classifier\n",
    "nb_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_df=0.9,\n",
    "        min_df=50\n",
    "    )),\n",
    "    (\"nb\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# define cross validation\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scoring metrics\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\"\n",
    "}\n",
    "# run cross validation\n",
    "cv_results = cross_validate(\n",
    "    nb_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           3.379223\n",
       "score_time         0.618406\n",
       "test_accuracy      0.927837\n",
       "train_accuracy     0.931977\n",
       "test_precision     0.920231\n",
       "train_precision    0.924411\n",
       "test_recall        0.920009\n",
       "train_recall       0.925039\n",
       "test_f1            0.920113\n",
       "train_f1           0.924725\n",
       "dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see results for cross validation\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "cv_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   True news       0.93      0.94      0.93      4239\n",
      "   Fake news       0.92      0.91      0.92      3491\n",
      "\n",
      "    accuracy                           0.93      7730\n",
      "   macro avg       0.93      0.92      0.93      7730\n",
      "weighted avg       0.93      0.93      0.93      7730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train on whole training set\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# run predictions on test set\n",
    "y_test_pred = nb_pipeline.predict(X_test)\n",
    "\n",
    "# print results\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_test_pred,\n",
    "    target_names=[\"True news\", \"Fake news\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXAMINE IMPORTANT WORDS FOR NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words indicating Fake news:\n",
      "\n",
      "              log_odds_fake_vs_true\n",
      "featured                   4.321071\n",
      "gop                        3.731271\n",
      "com                        3.533362\n",
      "image                      3.490896\n",
      "acr                        3.480959\n",
      "hannity                    3.451007\n",
      "fjs                        3.450252\n",
      "bundy                      3.395774\n",
      "screengrab                 3.388768\n",
      "somodevilla                3.386792\n",
      "hilarious                  3.382441\n",
      "boiler                     3.381462\n",
      "cops                       3.371698\n",
      "maher                      3.349387\n",
      "shit                       3.207256\n",
      "2017the                    3.200610\n",
      "pundit                     3.128580\n",
      "screen                     3.111864\n",
      "literally                  3.106908\n",
      "reilly                     3.086505\n",
      "images                     3.083379\n",
      "ck                         3.075353\n",
      "ass                        3.070105\n",
      "disgusting                 3.035628\n",
      "angerer                    3.030297\n",
      "mcnamee                    2.970642\n",
      "rant                       2.970358\n",
      "gonna                      2.970160\n",
      "racists                    2.955799\n",
      "youtube                    2.954975\n",
      "rep                        2.947509\n",
      "tapper                     2.917238\n",
      "damn                       2.911024\n",
      "cop                        2.867137\n",
      "funny                      2.856678\n",
      "racist                     2.855890\n",
      "caller                     2.852779\n",
      "wire                       2.847443\n",
      "carlson                    2.825576\n",
      "subscribe                  2.819825\n",
      "antifa                     2.789222\n",
      "2017trump                  2.779021\n",
      "bigoted                    2.778617\n",
      "2016featured               2.778447\n",
      "henningsen                 2.764185\n",
      "2016the                    2.759598\n",
      "bigots                     2.754140\n",
      "sh                         2.747036\n",
      "pathetic                   2.741109\n",
      "bullshit                   2.740047\n",
      "\n",
      "Top words indicating True news:\n",
      "\n",
      "               log_odds_fake_vs_true\n",
      "myanmar                    -4.328375\n",
      "rohingya                   -4.179502\n",
      "catalan                    -3.722721\n",
      "catalonia                  -3.686497\n",
      "hariri                     -3.571610\n",
      "mugabe                     -3.491536\n",
      "puigdemont                 -3.483653\n",
      "rakhine                    -3.414789\n",
      "reuters                    -3.379137\n",
      "spd                        -3.354884\n",
      "zuma                       -3.328119\n",
      "kurdish                    -3.263948\n",
      "ite                        -3.165173\n",
      "edt                        -3.148524\n",
      "kirkuk                     -3.139395\n",
      "parliamentary              -3.135736\n",
      "ministry                   -3.120840\n",
      "fdp                        -3.099799\n",
      "shi                        -3.090444\n",
      "ria                        -3.068528\n",
      "km                         -3.065338\n",
      "kurdistan                  -3.049681\n",
      "odinga                     -3.038372\n",
      "gmt                        -3.031936\n",
      "beijing                    -3.025322\n",
      "rajoy                      -3.019488\n",
      "spain                      -3.018934\n",
      "eu                         -3.013455\n",
      "parliament                 -3.006786\n",
      "mnangagwa                  -2.984116\n",
      "ly                         -2.931290\n",
      "referendum                 -2.928249\n",
      "bangladesh                 -2.910265\n",
      "gulen                      -2.904651\n",
      "sap                        -2.896386\n",
      "euro                       -2.888815\n",
      "cambodia                   -2.880198\n",
      "temer                      -2.864890\n",
      "graft                      -2.856711\n",
      "ankara                     -2.854735\n",
      "kurz                       -2.839148\n",
      "juncker                    -2.837069\n",
      "suu                        -2.823734\n",
      "rauner                     -2.819914\n",
      "kyi                        -2.814139\n",
      "xi                         -2.772828\n",
      "anc                        -2.768469\n",
      "2019                       -2.745913\n",
      "xinhua                     -2.744984\n",
      "corrects                   -2.714870\n"
     ]
    }
   ],
   "source": [
    "# get components from pipeline\n",
    "vectorizer = nb_pipeline.named_steps[\"tfidf\"]\n",
    "nb_model = nb_pipeline.named_steps[\"nb\"]\n",
    "\n",
    "# extract words\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log probabilities per class\n",
    "log_probs = nb_model.feature_log_prob_\n",
    "\n",
    "# create dataframe for results\n",
    "df_log_probs = pd.DataFrame(\n",
    "    log_probs.T,\n",
    "    index=feature_names,\n",
    "    columns=[\"True news\", \"Fake news\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the difference between classes\n",
    "df_log_probs[\"log_odds_fake_vs_true\"] = (\n",
    "    df_log_probs[\"Fake news\"] - df_log_probs[\"True news\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top words for fake news\n",
    "top_fake_nb = (\n",
    "    df_log_probs\n",
    "    .sort_values(\"log_odds_fake_vs_true\", ascending=False)\n",
    "    .head(50)\n",
    ")\n",
    "\n",
    "# top words for true news\n",
    "top_true_nb = (\n",
    "    df_log_probs\n",
    "    .sort_values(\"log_odds_fake_vs_true\", ascending=True)\n",
    "    .head(50)\n",
    ")\n",
    "\n",
    "print(\"Top words indicating Fake news:\\n\")\n",
    "print(top_fake_nb[[\"log_odds_fake_vs_true\"]])\n",
    "\n",
    "print(\"\\nTop words indicating True news:\\n\")\n",
    "print(top_true_nb[[\"log_odds_fake_vs_true\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 CENTROID-BASED CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed9350e2c5e4086bf60af5397217f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# embed training data\n",
    "X_train_embeddings = embedding_model.encode(\n",
    "    X_train.tolist(),\n",
    "    show_progress_bar=True\n",
    ")\n",
    "# convert targets to array\n",
    "y_train_array = y_train.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute class-centroids\n",
    "true_centroid = X_train_embeddings[y_train_array == 0].mean(axis=0)\n",
    "fake_centroid = X_train_embeddings[y_train_array == 1].mean(axis=0)\n",
    "\n",
    "# reshape for cosine similarity\n",
    "true_centroid = true_centroid.reshape(1, -1)\n",
    "fake_centroid = fake_centroid.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d111c9f8f034de1a6c6a404f3895728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# embed test data\n",
    "X_test_embeddings = embedding_model.encode(\n",
    "    X_test.tolist(),\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classification logic\n",
    "def centroid_predict(embeddings, true_centroid, fake_centroid):\n",
    "    sim_true = cosine_similarity(embeddings, true_centroid).flatten()\n",
    "    sim_fake = cosine_similarity(embeddings, fake_centroid).flatten()\n",
    "    \n",
    "    # predict class with highest similarity\n",
    "    return np.where(sim_fake > sim_true, 1, 0)\n",
    "\n",
    "# predict on test set \n",
    "y_pred_centroid = centroid_predict(\n",
    "    X_test_embeddings,\n",
    "    true_centroid,\n",
    "    fake_centroid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   True news       0.88      0.81      0.84      4239\n",
      "   Fake news       0.79      0.87      0.83      3491\n",
      "\n",
      "    accuracy                           0.84      7730\n",
      "   macro avg       0.84      0.84      0.84      7730\n",
      "weighted avg       0.84      0.84      0.84      7730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred_centroid,\n",
    "    target_names=[\"True news\", \"Fake news\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between class centroids: 0.83728975\n"
     ]
    }
   ],
   "source": [
    "# investigate distance between class centroids \n",
    "centroid_similarity = cosine_similarity(true_centroid, fake_centroid)[0, 0]\n",
    "print(\"Cosine similarity between class centroids:\", centroid_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity to centroids for test set\n",
    "sim_true = cosine_similarity(X_test_embeddings, true_centroid).flatten()\n",
    "sim_fake = cosine_similarity(X_test_embeddings, fake_centroid).flatten()\n",
    "\n",
    "analysis_df = pd.DataFrame({\n",
    "    \"text\": X_test.values,\n",
    "    \"true_label\": y_test.values,\n",
    "    \"sim_true\": sim_true,\n",
    "    \"sim_fake\": sim_fake,\n",
    "    \"pred_label\": y_pred_centroid\n",
    "})\n",
    "\n",
    "# compute margin to both classes for each observation \n",
    "analysis_df[\"margin\"] = analysis_df[\"sim_fake\"] - analysis_df[\"sim_true\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>sim_true</th>\n",
       "      <th>sim_fake</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>the audio of hillary clinton laughing about ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323283</td>\n",
       "      <td>0.579262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>as much as he and his supporters want to say t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.438703</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6638</th>\n",
       "      <td>something that donald trump needs to realize i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407673</td>\n",
       "      <td>0.654227</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>tomi lahren literally thinks the beating of a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305683</td>\n",
       "      <td>0.551805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>when donald trump isn t getting blasted for hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418764</td>\n",
       "      <td>0.659268</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  true_label  sim_true  \\\n",
       "2874  the audio of hillary clinton laughing about ge...           1  0.323283   \n",
       "2154  as much as he and his supporters want to say t...           1  0.438703   \n",
       "6638  something that donald trump needs to realize i...           1  0.407673   \n",
       "2573  tomi lahren literally thinks the beating of a ...           1  0.305683   \n",
       "3538  when donald trump isn t getting blasted for hi...           1  0.418764   \n",
       "\n",
       "      sim_fake  pred_label    margin  \n",
       "2874  0.579262           1  0.255979  \n",
       "2154  0.687600           1  0.248897  \n",
       "6638  0.654227           1  0.246554  \n",
       "2573  0.551805           1  0.246121  \n",
       "3538  0.659268           1  0.240503  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very confident fake predictions\n",
    "analysis_df.sort_values(\"margin\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>sim_true</th>\n",
       "      <th>sim_fake</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>iran is fulfilling its commitments under the n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522831</td>\n",
       "      <td>0.273593</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>turkey will take the resolution calling on the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477216</td>\n",
       "      <td>0.229957</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>the united states could shortly broaden talks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525830</td>\n",
       "      <td>0.281796</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.244034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>libyan factions involved in u.n.-brokered peac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500797</td>\n",
       "      <td>0.261284</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.239513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>china has proposed a three-phase plan for reso...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411447</td>\n",
       "      <td>0.172409</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.239038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  true_label  sim_true  \\\n",
       "5204  iran is fulfilling its commitments under the n...           0  0.522831   \n",
       "5854  turkey will take the resolution calling on the...           0  0.477216   \n",
       "485   the united states could shortly broaden talks ...           0  0.525830   \n",
       "5316  libyan factions involved in u.n.-brokered peac...           0  0.500797   \n",
       "2927  china has proposed a three-phase plan for reso...           0  0.411447   \n",
       "\n",
       "      sim_fake  pred_label    margin  \n",
       "5204  0.273593           0 -0.249238  \n",
       "5854  0.229957           0 -0.247259  \n",
       "485   0.281796           0 -0.244034  \n",
       "5316  0.261284           0 -0.239513  \n",
       "2927  0.172409           0 -0.239038  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very confident true predictions\n",
    "analysis_df.sort_values(\"margin\", ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>sim_true</th>\n",
       "      <th>sim_fake</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>republican presidential front-runner donald tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463641</td>\n",
       "      <td>0.468088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>donald trump brought his message of walls and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493613</td>\n",
       "      <td>0.535861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>when hillary clinton first ran for president i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.427209</td>\n",
       "      <td>0.522503</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>admitting somalis who d been settled for years...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292669</td>\n",
       "      <td>0.180809</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.111860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>like the soldiers of oden vigilante group we r...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352111</td>\n",
       "      <td>0.294505</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.057605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a top aide to u.s. president donald trump on s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567558</td>\n",
       "      <td>0.654247</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the hill released controversial comments sore ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624234</td>\n",
       "      <td>0.557003</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.067232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>the following statements were posted to the ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520369</td>\n",
       "      <td>0.535069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>british police said they have evacuated and ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067385</td>\n",
       "      <td>0.068492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>south korean police have arrested the owner an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240778</td>\n",
       "      <td>0.267489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  true_label  sim_true  \\\n",
       "4   republican presidential front-runner donald tr...           0  0.463641   \n",
       "8   donald trump brought his message of walls and ...           0  0.493613   \n",
       "13  when hillary clinton first ran for president i...           0  0.427209   \n",
       "15  admitting somalis who d been settled for years...           1  0.292669   \n",
       "18  like the soldiers of oden vigilante group we r...           1  0.352111   \n",
       "24  a top aide to u.s. president donald trump on s...           0  0.567558   \n",
       "27  the hill released controversial comments sore ...           1  0.624234   \n",
       "31  the following statements were posted to the ve...           0  0.520369   \n",
       "35  british police said they have evacuated and ar...           0  0.067385   \n",
       "36  south korean police have arrested the owner an...           0  0.240778   \n",
       "\n",
       "    sim_fake  pred_label    margin  \n",
       "4   0.468088           1  0.004446  \n",
       "8   0.535861           1  0.042248  \n",
       "13  0.522503           1  0.095294  \n",
       "15  0.180809           0 -0.111860  \n",
       "18  0.294505           0 -0.057605  \n",
       "24  0.654247           1  0.086689  \n",
       "27  0.557003           0 -0.067232  \n",
       "31  0.535069           1  0.014700  \n",
       "35  0.068492           1  0.001106  \n",
       "36  0.267489           1  0.026711  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# misclassified articles\n",
    "analysis_df[analysis_df[\"true_label\"] != analysis_df[\"pred_label\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ZERO-SHOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "# load zero-shot classifier\n",
    "zero_shot = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=\"mps\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels \n",
    "candidate_labels = [\"fake news\", \"real news\"]\n",
    "\n",
    "# extract subset\n",
    "subset_size = 500\n",
    "\n",
    "X_test_subset = X_test.sample(\n",
    "    n=subset_size,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "y_test_subset = y_test.loc[X_test_subset.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  define decision logic\n",
    "def zero_shot_predict(texts):\n",
    "    outputs = zero_shot(texts, candidate_labels)\n",
    "    return np.array([\n",
    "        1 if o[\"labels\"][0] == \"fake news\" else 0\n",
    "        for o in outputs\n",
    "    ])\n",
    "\n",
    "y_pred_zs = zero_shot_predict(X_test_subset.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   True news       0.39      0.24      0.30       287\n",
      "   Fake news       0.33      0.50      0.40       213\n",
      "\n",
      "    accuracy                           0.35       500\n",
      "   macro avg       0.36      0.37      0.35       500\n",
      "weighted avg       0.36      0.35      0.34       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(classification_report(\n",
    "    y_test_subset,\n",
    "    y_pred_zs,\n",
    "    target_names=[\"True news\", \"Fake news\"]\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
